# Plant_species_identification
### Title: Artificial vision models for the identification of Mediterranean flora: an analysis in four ecosystems

This repository contains the implementation steps for our experimental study on plant species identification. Our study quantitatively evaluates the performance of six popular object detection models on our dataset collected in the wild, comprising various plant species from four habitats: screes, dunes, grasslands, and forests. The dataset employed in this work includes the data collected by human operators and the quadrupedal robot ANYmal C. The pre-trained (on COCO dataset) object detection models have been chosen for experiments, and they are fine-tuned on our dataset. These models incorporate two one-stage (**RetinaNet** and **YOLOv8n**), two two-stage (**Faster RCNN** and **Cascade RCNN**), and two transformer-based detectors (**DETR** and **Deformable DETR**). We have performed the experiments on the four habitat datasets by applying class balancing and hyperparameter tuning. 

The implementation of the five methods, except YOLO, has been performed in [MMDetection 2.x Toolbox](https://arxiv.org/abs/1906.07155). The specific configuration for each of the models implemented in MMDetection is presented in the attached Table **MMDetection_models_configuration**. The columns in the table include technique, backbone used in that technique, type of network or attention heads(AHs) and transformer layers (TLs) in case of transformer-based methods, training schedule or duration, learning rate, optimizer, weight decay (it is *0.0001* for all methods), momentum, and the maximum number of epochs for which the model has been trained. The training schedule *1x* means that the model has been trained for one epoch over the dataset. However, training durations *150e* and *50e* depict that the model is trained for *150* epochs and *50* epochs over the dataset, respectively. Under the *Network* column, *FPN* represents Feature Pyramid Network, *AHs* and *TLs* mean Attention Heads and Transformer Layers, respectively.

YOLOv8 has been implemented separately with the help of its [GitHub](https://github.com/ultralytics) repository. The documentation of YOLOv8 can be found [here](https://docs.ultralytics.com/). The attached Table **YOLO_configuration** shows the YOLOv8 hyperparameter values for diverse model training for all the habitats. The first column has all the hyperparameters, and the second column shows the default values used in YOLOv8 architecture, which are the same for all habitats. The subsequent columns present the different hyperparameter values for two settings: *200e*, *10iter* and *100e*, *20iter*. The setting *200e* and *10iter* means that the hyperparameter tuning has been performed on YOLO for *10* iterations and *200* epochs; similarly, *100e* and *20iter* represent *20* iterations and *100* epochs. After getting the best hyperparameters for a particular setting, YOLO was trained separately for each habitat using those hyperparameter values for *200* epochs. YOLO has been trained with default parameters for *500* epochs with the patience of *50*. 

[MMDetection Github](https://github.com/open-mmlab/mmdetection)
[YOLOv8 Github](https://github.com/ultralytics)

The dataset utilised in this study can be found [here](https://zenodo.org/records/11504938).

To be updated...
