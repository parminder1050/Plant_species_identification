# Mediterranean Plant Species Identification

This repository contains the implementation steps for our experimental study on plant species identification. Our study quantitatively evaluates the performance of six popular object detection models on our dataset collected in the wild, comprising various plant species from four habitats: screes, dunes, grasslands, and forests. The dataset employed in this work includes the data collected by human operators and the quadrupedal robot ANYmal C. The pre-trained (on COCO dataset) object detection models have been chosen for experiments, and they are fine-tuned on our dataset. These models incorporate two one-stage (**RetinaNet** and **YOLOv8n**), two two-stage (**Faster RCNN** and **Cascade RCNN**), and two transformer-based detectors (**DETR** and **Deformable DETR**). We have performed experiments on the four habitat datasets by applying class balancing and hyperparameter tuning. 

The implementation of the five methods, except YOLO, has been performed in [MMDetection 2.x Toolbox](https://arxiv.org/abs/1906.07155). The specific configuration for each of the models implemented in MMDetection is presented in the attached Table **MMDetection_models_configuration**. The columns in the table include technique, backbone used in that technique, type of network or attention heads (AHs) and transformer layers (TLs) in case of transformer-based methods, training schedule or duration, learning rate, optimizer, weight decay (it is *0.0001* for all methods), momentum, and the maximum number of epochs for which the model has been trained. The training schedule *1x* means that the model has been trained for one epoch over the dataset. However, the training durations *150e* and *50e* indicate that the model was trained for *150* and *50* epochs over the dataset, respectively. Under the *Network* column, *FPN* represents Feature Pyramid Network, *AHs* and *TLs* mean Attention Heads and Transformer Layers, respectively.

YOLOv8 has been implemented separately using its [GitHub](https://github.com/ultralytics) repository. The documentation of YOLOv8 can be found [here](https://docs.ultralytics.com/). The attached Table **YOLO_configuration** shows the YOLOv8 hyperparameter values for diverse model training for all the habitats. The first column has all the hyperparameters, and the second column shows the default values used in YOLOv8 architecture, which are the same for all habitats. The subsequent columns present the different hyperparameter values for two settings: *200e*, *10iter* and *100e*, *20iter*. The settings *200e* and *10iter* indicate that hyperparameter tuning was performed on YOLO for *10* iterations and *200* epochs; similarly, *100e* and *20iter* indicate *20* iterations and *100* epochs. After determining the best hyperparameters for a particular setting, YOLO was trained separately for each habitat using those hyperparameters for *200* epochs. YOLO has been trained with default parameters for *500* epochs with the patience of *50*. 

[MMDetection Github](https://github.com/open-mmlab/mmdetection)

[YOLOv8 Github](https://github.com/ultralytics)

The dataset utilised in this study can be found [here](https://zenodo.org/records/11504938). The sample data can be viewed in the attached image **dataset**. 

### If you find this repository useful, please cite the article below.

@article{kaur2025artificial, title={Artificial vision models for the identification of Mediterranean flora: An analysis in four ecosystems}, author={Kaur, Parminder and Grassi, Anna and Bonini, Federica and Valle, Barbara and Borgatti, Marina Serena and Rivieccio, Giovanni and Denaro, Agnese and De Simone, Leopoldo and Fanfarillo, Emanuele and Remagnino, Paolo}, journal={PloS one}, volume={20}, number={9}, pages={e0327969}, year={2025}, publisher={Public Library of Science San Francisco, CA USA}
}
